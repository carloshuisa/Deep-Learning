
from sklearn.datasets.samples_generator import make_blobs
from sklearn.metrics import accuracy_score
from keras.models import load_model
from keras.utils import to_categorical
from keras.utils import plot_model
from keras.models import Model
from keras.layers import Input
from keras.layers import Dense
from keras.layers.merge import concatenate
from numpy import argmax
 
# cargamos los modelos 
def load_all_models(n_models):
	all_models = list()
	for i in range(n_models):
		# define filename for this ensemble
		filename = 'models/model_' + str(i + 1) + '.h5'
		# load model from file
		model = load_model(filename)
		# add to list of members
		all_models.append(model)
		print('>loaded %s' % filename)
	return all_models
 
# definimos el modelo de Stacking
def define_stacked_model(members):
	# actualizar todas las capas de los modelos base para que no sean entrenables
	for i in range(len(members)):
		model = members[i]
		for layer in model.layers:
			layer.trainable = False
			layer.name = 'ensemble_' + str(i+1) + '_' + layer.name
      
	# definimos el input del meta-modelo
	ensemble_visible = [model.input for model in members]
	# concatenamos los outputs de los modelos base
	ensemble_outputs = [model.output for model in members]
	merge = concatenate(ensemble_outputs)
	hidden = Dense(10, activation='relu')(merge)
	output = Dense(3, activation='softmax')(hidden)
	model = Model(inputs=ensemble_visible, outputs=output)
	# graficamos el modelo ensamblado
	plot_model(model, show_shapes=True, to_file='model_graph.png')
	# creamos el modelo
	model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
	return model
 
# entrenamos el modelo de stacking
def fit_stacked_model(model, inputX, inputy):
	X = [inputX for _ in range(len(model.input))]
	inputy_enc = to_categorical(inputy)
	model.fit(X, inputy_enc, epochs=300, verbose=0)
 
# realizamos la prediccion con el modelo ensamblado
def predict_stacked_model(model, inputX):
	X = [inputX for _ in range(len(model.input))]
	return model.predict(X, verbose=0)
 
# generamos el dataset de 2 variables
X, y = make_blobs(n_samples=1100, centers=3, n_features=2, cluster_std=2, random_state=2)
# dividimos en train y test
n_train = 100
trainX, testX = X[:n_train, :], X[n_train:, :]
trainy, testy = y[:n_train], y[n_train:]
print(trainX.shape, testX.shape)
# cargamos todos los modelos
n_members = 5
members = load_all_models(n_members)
print('Loaded %d models' % len(members))
# definimos el modelo ensamble
stacked_model = define_stacked_model(members)
# entrenamos el modelo ensamblado
fit_stacked_model(stacked_model, testX, testy)
# realizamos la predicciones y evaluamos
yhat = predict_stacked_model(stacked_model, testX)
yhat = argmax(yhat, axis=1)
acc = accuracy_score(testy, yhat)
print('Stacked Test Accuracy: %.3f' % acc)
